{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqDU98ufTgaP"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torch-geometric pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv\n"
      ],
      "metadata": {
        "id": "DzSEFm60TpxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k/u.data\"\n",
        "\n",
        "# Load data with pandas\n",
        "df = pd.read_csv(\"u.data\", sep=\"\\t\", header=None, names=[\"user\", \"item\", \"rating\", \"timestamp\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOGFK-yVTwz-",
        "outputId": "ad187014-dbbf-4ed2-930e-93203fae2a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-14 08:30:39--  http://files.grouplens.org/datasets/movielens/ml-100k/u.data\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1979173 (1.9M)\n",
            "Saving to: ‘u.data’\n",
            "\n",
            "\ru.data                0%[                    ]       0  --.-KB/s               \ru.data              100%[===================>]   1.89M  11.1MB/s    in 0.2s    \n",
            "\n",
            "2023-10-14 08:30:40 (11.1 MB/s) - ‘u.data’ saved [1979173/1979173]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ-KRlN2V-ow",
        "outputId": "e31a8ec6-85c7-4c95-b94e-a76a4b0fa8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user  item  rating  timestamp\n",
            "0   196   242       3  881250949\n",
            "1   186   302       3  891717742\n",
            "2    22   377       1  878887116\n",
            "3   244    51       2  880606923\n",
            "4   166   346       1  886397596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process data\n",
        "users = torch.tensor(df[\"user\"].values, dtype=torch.long) - 1  # 0-indexed\n",
        "items = torch.tensor(df[\"item\"].values, dtype=torch.long) - 1  # 0-indexed\n",
        "edge_index = torch.stack([users, items + df[\"user\"].nunique()], dim=0)  # Offset for unique item IDs\n",
        "\n",
        "# Create PyG Data object\n",
        "data = Data(edge_index=edge_index)\n"
      ],
      "metadata": {
        "id": "0UWHSUe_TzMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GNN Model\n",
        "class RecommenderGNN(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, input_dim, hidden_dim, output_dim):\n",
        "        super(RecommenderGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Model, Data, and Optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = RecommenderGNN(num_nodes=df[\"user\"].nunique() + df[\"item\"].nunique(),\n",
        "                       input_dim=32, hidden_dim=64, output_dim=32).to(device)\n",
        "\n",
        "# Update the node features initialization\n",
        "data.x = torch.randn((df[\"user\"].nunique() + df[\"item\"].nunique(), 32)).to(device)  # Random initial features\n"
      ],
      "metadata": {
        "id": "32yZdNhJT36a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GNN\n",
        "model.train()\n",
        "for epoch in range(30):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.mse_loss(out, data.x)  # Autoencoder approach\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X8Y5STuT8s6",
        "outputId": "cc62e8da-6af5-4b0e-d49e-d6374674d044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.773842811584473\n",
            "Epoch 2, Loss: 7.773842811584473\n",
            "Epoch 3, Loss: 7.773842811584473\n",
            "Epoch 4, Loss: 7.773842811584473\n",
            "Epoch 5, Loss: 7.773842811584473\n",
            "Epoch 6, Loss: 7.773842811584473\n",
            "Epoch 7, Loss: 7.773842811584473\n",
            "Epoch 8, Loss: 7.773842811584473\n",
            "Epoch 9, Loss: 7.773842811584473\n",
            "Epoch 10, Loss: 7.773842811584473\n",
            "Epoch 11, Loss: 7.773842811584473\n",
            "Epoch 12, Loss: 7.773842811584473\n",
            "Epoch 13, Loss: 7.773842811584473\n",
            "Epoch 14, Loss: 7.773842811584473\n",
            "Epoch 15, Loss: 7.773842811584473\n",
            "Epoch 16, Loss: 7.773842811584473\n",
            "Epoch 17, Loss: 7.773842811584473\n",
            "Epoch 18, Loss: 7.773842811584473\n",
            "Epoch 19, Loss: 7.773842811584473\n",
            "Epoch 20, Loss: 7.773842811584473\n",
            "Epoch 21, Loss: 7.773842811584473\n",
            "Epoch 22, Loss: 7.773842811584473\n",
            "Epoch 23, Loss: 7.773842811584473\n",
            "Epoch 24, Loss: 7.773842811584473\n",
            "Epoch 25, Loss: 7.773842811584473\n",
            "Epoch 26, Loss: 7.773842811584473\n",
            "Epoch 27, Loss: 7.773842811584473\n",
            "Epoch 28, Loss: 7.773842811584473\n",
            "Epoch 29, Loss: 7.773842811584473\n",
            "Epoch 30, Loss: 7.773842811584473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make recommendations\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(data)\n",
        "    user_embeddings = embeddings[:df[\"user\"].nunique()]\n",
        "    item_embeddings = embeddings[df[\"user\"].nunique():]\n",
        "    scores = torch.mm(user_embeddings, item_embeddings.t())\n",
        "    _, recommendations = scores.topk(5, dim=1)\n",
        "    print(recommendations)  # These are item IDs (0-indexed) recommended for each user\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwHlYfv9UPUl",
        "outputId": "6c5d83d7-1cee-4bb6-9b3e-cf2fd5d42124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 49, 180,  99, 257,   0],\n",
            "        [ 49, 257,  99, 180, 293],\n",
            "        [ 49, 180,  99, 257,   0],\n",
            "        ...,\n",
            "        [ 49,  99, 180, 287, 293],\n",
            "        [ 49, 287, 293, 257,  99],\n",
            "        [ 49, 180,  99,   0, 257]])\n"
          ]
        }
      ]
    }
  ]
}